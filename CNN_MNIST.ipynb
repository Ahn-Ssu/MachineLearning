{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_practice.ipynb","version":"0.3.2","provenance":[{"file_id":"1OuZwYHiFS3SdApVtP6Hzyt7mb65OVZRM","timestamp":1553673049050},{"file_id":"https://github.com/Yangyangii/pytorch-practice/blob/master/DNN.ipynb","timestamp":1553414179628}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"W7zsPERtr0LC","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Nets (CNN)"]},{"metadata":{"id":"9iL5KH63r0LE","colab_type":"code","colab":{}},"cell_type":"code","source":["# If necessary, uncommand and run the following line to install pytorch\n","#!pip install torch torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dEBe8KzEr0LJ","colab_type":"text"},"cell_type":"markdown","source":["과거에는 Google Colab를 pytorch를 기본제공하지 않았으므로 Google Colab에서 pytorch를 사용하려면 먼저 pytorch를 설치해야 함.\n","\n","현재는 불필요함."]},{"metadata":{"id":"YbUmP-VGVvcP","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import datetime\n","#import os, sys"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QoPiqjikr0LT","colab_type":"text"},"cell_type":"markdown","source":["**numpy**는 다차원 배열 및 벡터/ 행렬 기본 연산\n","python으로 data science를 할 때 가장 기본이 되는 라이브러리 중 하나.\n","\n","**datetime** 학습/실행 시간 측정을 위한 package\n","\n","**os, sys**    os의 기능을 활용하기 위한 package"]},{"metadata":{"id":"kjpK8daar0LK","colab_type":"code","outputId":"c1df28e1-87d8-446a-ee0a-7cd61f63c446","executionInfo":{"status":"ok","timestamp":1554713172965,"user_tz":-540,"elapsed":1621,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import torch\n","import torchvision            \n","import torch.nn as nn\n","\n","print(torch.__version__)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["1.0.1.post2\n"],"name":"stdout"}]},{"metadata":{"id":"LhNkRvYkr0LN","colab_type":"text"},"cell_type":"markdown","source":["**torch**: pytorch package\n","\n","**torch.nn**: 신경망 모델에 Class들을 포함\n","\n","**torchvision**은 computer vision에 많이 사용되는 dataset, model, transform을 포함 (https://pytorch.org/docs/stable/torchvision/index.html)"]},{"metadata":{"id":"ntWD5II587og","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.utils.data import DataLoader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YgsGVrkrAEPD","colab_type":"text"},"cell_type":"markdown","source":["Data Loader: 데이터 로드를 위한 패키지 (Dataset + Sampler + Iterator)\n","> * Dataset is an abstract class representing a dataset \n","> * Sampler provides a way to iterate over indices of dataset elements\n","\n","\n","See https://pytorch.org/docs/stable/data.html"]},{"metadata":{"id":"_tUvuvvPr0LO","colab_type":"code","colab":{}},"cell_type":"code","source":["from torchvision import datasets\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Odn-STAQAmKq","colab_type":"text"},"cell_type":"markdown","source":["**dataset**: MNIST, fashion MNIST, COCO, LSUN, CIFAR, etc.\n","\n","**transforms**: algorithms for preprocessing or data augmentation\n","\n","See https://pytorch.org/docs/stable/torchvision/index.html to know datasets and transforms in torchvision"]},{"metadata":{"id":"mtKXCay2kN5Z","colab_type":"text"},"cell_type":"markdown","source":["# Using (deep) neural networks with python\n","\n","\n","1. Define a network model\n","\n","2. Prepare data\n","\n","3. Train the model\n","\n","4. Evalute the model"]},{"metadata":{"id":"eCc7O8M5r0LT","colab_type":"code","colab":{}},"cell_type":"code","source":["#import matplotlib\n","\n","%matplotlib inline\n","from matplotlib.pyplot import imshow, imsave"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qgaevoCUr0LW","colab_type":"text"},"cell_type":"markdown","source":["**matplotlib**: python visualization library"]},{"metadata":{"id":"hYk9uq_Br0LW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"20b213e9-a499-4cd2-c89e-ddd7158b5905","executionInfo":{"status":"ok","timestamp":1554713172979,"user_tz":-540,"elapsed":1577,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}}},"cell_type":"code","source":["MODEL_NAME = 'DNN'\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["MODEL_NAME = DNN, DEVICE = cuda\n"],"name":"stdout"}]},{"metadata":{"id":"AhUqWS9-r0La","colab_type":"text"},"cell_type":"markdown","source":["GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n","\n","**torch.cuda.is_avaliable()**은 GPU가 사용가능한지를 판단하는 함수"]},{"metadata":{"id":"8ljFCGEIXfCy","colab_type":"text"},"cell_type":"markdown","source":["## Defining a Neural Network model using pytorch\n","\n","1. Define a neural net model\n","\n","> * Define a model class inheriting **nn.module**\n","\n",">> nn.module is the base class of all layers/operators\n","\n",">* Define **__init__** function (constructor)\n","\n",">>  Create layers and operators\n","\n",">* Define **forward** function (forward propagation)\n","\n",">> Define how to compute the output from the input\n","\n","> Example\n","\n","~~~~\n","    class Model(nn.Module):\n","        def __init__(self):\n","            super(Model, self).__init__()\n","            self.conv1 = nn.Conv2d(1, 20, 5)\n","            self.conv2 = nn.Conv2d(20, 20, 5)           \n","                   \n","        def forward(self, x):\n","            x = F.relu(self.conv1(x))\n","            return F.relu(self.conv2(x))\n","~~~~\n","\n","> Note! You don't need to backpropagation procedure, because pytorch provides **autograd**"]},{"metadata":{"id":"sbpvoKXzr0Lb","colab_type":"code","colab":{}},"cell_type":"code","source":["class HelloCNN(nn.Module):\n","    \"\"\"\n","        Simple CNN Clssifier\n","    \"\"\"\n","    def __init__(self, num_classes=10):\n","        super(HelloCNN, self).__init__()\n","        \n","        self.conv = nn.Sequential(\n","            # (N, 1, 28, 28)\n","            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            # (N, 32, 14, 14)\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            # (N, 64, 7, 7)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(7*7*64, 512),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(512, num_classes),\n","        )\n","        \n","    def forward(self, x):\n","        y_ = self.conv(x) # (N, 64, 7, 7)\n","        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n","        y_ = self.fc(y_)\n","        return y_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BfM4wnwdr0Le","colab_type":"text"},"cell_type":"markdown","source":["**nn.Sequential()**: a sequential container.\n","\n","* Example of using Sequential\n","\n","~~~~\n","  model = nn.Sequential(\n","    nn.Conv2d(1,20,5),\n","    nn.ReLU(),\n","    nn.Conv2d(20,64,5),\n","    nn.ReLU()\n","    )\n","~~~~\n","* Example of using Sequential with OrderedDict\n","\n","~~~~\n","  model = nn.Sequential(OrderedDict([\n","    ('conv1', nn.Conv2d(1,20,5)),\n","    ('relu1', nn.ReLU()),\n","    ('conv2', nn.Conv2d(20,64,5)),\n","    ('relu2', nn.ReLU())\n","    ]))\n","~~~~\n","\n","**nn.ModuleList**: a list-like container class \n","\n","* Example of using ModuleList\n","\n","~~~~\n","  class MyModule(nn.Module):\n","      def __init__(self):\n","          super(MyModule, self).__init__()\n","          self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n","            \n","      def forward(self, x):\n","          # ModuleList can act as an iterable, or be indexed using ints\n","          for i, l in enumerate(self.linears):\n","               x = self.linears[i // 2](x) + l(x)\n","          return x\n","                 \n","~~~~"]},{"metadata":{"id":"fyP-DP1Sr0Lh","colab_type":"code","colab":{}},"cell_type":"code","source":["model = HelloCNN().to(DEVICE)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cyyU-712c1Np","colab_type":"text"},"cell_type":"markdown","source":["Moves and/or casts the parameters and buffers. (CPU or GPU)"]},{"metadata":{"id":"Z9-QvNvbksQj","colab_type":"text"},"cell_type":"markdown","source":["## Loading and preprocessing of data\n","\n"]},{"metadata":{"id":"Glhmh_OHlBMY","colab_type":"text"},"cell_type":"markdown","source":["Transform of input data"]},{"metadata":{"id":"oq2EYzdBr0Lk","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),                               # image to tensor\n","     transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # normalize to \"(x-mean)/std\"\n","    ])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vbb9TUIOz3tb","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"sT2-XwiU9Xnc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2hE6ydS3r0Lm","colab_type":"text"},"cell_type":"markdown","source":["**transforms**: torchvision에서 제공하는 transform 함수들이 있는 패키지.\n","\n","**ToTensor**: numpy array를 torch tensor로 변환.\n","\n","**Normalize**: 정규화 함수 output[channel] = (input[channel] - mean[channel]) / std[channel]"]},{"metadata":{"id":"buibF906r0Lm","colab_type":"code","colab":{}},"cell_type":"code","source":["mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n","mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lYL_NEavr0Lo","colab_type":"text"},"cell_type":"markdown","source":["**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n","\n","root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."]},{"metadata":{"id":"wGbeeCkCr0Lp","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 64"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6_n0AFCmr0Lr","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GR9GEof0r0Ls","colab_type":"text"},"cell_type":"markdown","source":["**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n","\n","**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n","\n","**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."]},{"metadata":{"id":"YH-t5coUmuOM","colab_type":"text"},"cell_type":"markdown","source":["## Training neural network model\n","\n","\n","Training procedure\n","~~~~\n","for epoch in range(max_epoch):\n","    for input, target in dataset:    # retrieve input data and target labels\n","        optimizer.zero_grad()     # reset gradient\n","        output = model(input)     # forward propagation\n","        loss = loss_fn(output, target)  # get loss value\n","        loss.backward()           # back-propagation (compute gradient)     optimizer.step()          # update parameters with gradient\n","~~~~"]},{"metadata":{"id":"eeNx2EZKFoBP","colab_type":"code","colab":{}},"cell_type":"code","source":["# utility function to measure time\n","\n","import time\n","import math\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pEt4xYD4r0Lt","colab_type":"code","colab":{}},"cell_type":"code","source":["# set loss function and optimizer\n","\n","criterion = nn.CrossEntropyLoss()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"waSS2hrKr0Lv","colab_type":"text"},"cell_type":"markdown","source":["**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n","\n","**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."]},{"metadata":{"id":"K4lF0ODwr0Lz","colab_type":"text"},"cell_type":"markdown","source":["### Training procedure\n","\n","첫번째 for문: 원하는 epoch만큼 반복\n","\n","두번째 for문: training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n","\n","**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n","\n","**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n","\n","**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n","\n","**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n","\n","**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n","\n","**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n","\n","**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n","\n","**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n","\n","**torch.no_grad (Line 19)**: gradient를 계산하기 위해 추적하는 수고를 하지 않음\n","\n","**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n","\n","**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"]},{"metadata":{"scrolled":true,"id":"-KAxJESir0L0","colab_type":"code","outputId":"cc04b755-3e49-4147-bd0c-cc915759f008","executionInfo":{"status":"ok","timestamp":1554713304040,"user_tz":-540,"elapsed":23404,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":467}},"cell_type":"code","source":["max_epoch = 5        # maximum number of epochs\n","step = 0             # initialize step counter variable\n","\n","start = time.time()\n","\n","for epoch in range(max_epoch):\n","    for idx, (images, labels) in enumerate(train_loader):\n","        # Training Discriminator\n","        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","        \n","        y_hat = model(x) # (N, 10)  # forward propagation\n","       \n","        loss = criterion(y_hat, y)  # computing loss\n","        \n","        optim.zero_grad()           # reset gradient\n","        loss.backward()             # back-propagation (compute gradient)\n","        optim.step()                # update parameters with gradient\n","        \n","        # periodically print loss\n","        if step % 500 == 0:\n","            print('Epoch({}): {}/{}, Step: {}, Loss: {}'.format(timeSince(start), epoch, max_epoch, step, loss.item()))\n","        \n","        # periodically evalute model on test data\n","        if step % 1000 == 0:\n","            model.eval()\n","            acc = 0.\n","            with torch.no_grad():   # disable autograd\n","                for idx, (images, labels) in enumerate(test_loader):\n","                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","                    y_hat = model(x) # (N, 10)\n","                    loss = criterion(y_hat, y)\n","                    _, indices = torch.max(y_hat, dim=-1)     # find maxmum along the last axis (argmax of each row)\n","                                                              # ex) max_value, max_idx = torch.max(input, dim)\n","                    acc += torch.sum(indices == y).item()     # count correctly classified samples\n","                                                              # torch.sum() returns Tensor. Tensor.item() converts it to a value\n","            print('*'*20, 'Test', '*'*20)\n","            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n","            print('*'*46)\n","            model.train()           # turn to train mode (enable autograd)\n","        step += 1"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch(0m 0s): 0/5, Step: 0, Loss: 2.3091328144073486\n","******************** Test ********************\n","Step: 0, Loss: 2.6400508880615234, Accuracy: 27.51 %\n","**********************************************\n","Epoch(0m 15s): 0/5, Step: 500, Loss: 0.02445429563522339\n","Epoch(0m 27s): 1/5, Step: 1000, Loss: 0.2160850465297699\n","******************** Test ********************\n","Step: 1000, Loss: 0.006645651068538427, Accuracy: 98.54 %\n","**********************************************\n","Epoch(0m 42s): 1/5, Step: 1500, Loss: 0.013537503778934479\n","Epoch(0m 54s): 2/5, Step: 2000, Loss: 0.02754722535610199\n","******************** Test ********************\n","Step: 2000, Loss: 0.007956237532198429, Accuracy: 98.9 %\n","**********************************************\n","Epoch(1m 9s): 2/5, Step: 2500, Loss: 0.020049042999744415\n","Epoch(1m 21s): 3/5, Step: 3000, Loss: 0.009810149669647217\n","******************** Test ********************\n","Step: 3000, Loss: 0.0004665851593017578, Accuracy: 98.92999999999999 %\n","**********************************************\n","Epoch(1m 36s): 3/5, Step: 3500, Loss: 0.05551809072494507\n","Epoch(1m 47s): 4/5, Step: 4000, Loss: 0.12057551741600037\n","******************** Test ********************\n","Step: 4000, Loss: 0.001505136489868164, Accuracy: 99.09 %\n","**********************************************\n","Epoch(2m 3s): 4/5, Step: 4500, Loss: 0.05058355629444122\n"],"name":"stdout"}]},{"metadata":{"id":"ta_UwyT1r0L6","colab_type":"text"},"cell_type":"markdown","source":["## Test and Visualize"]},{"metadata":{"id":"6AwZsqeJr0L6","colab_type":"code","outputId":"95896ce3-7700-4a5f-c509-a846e79ecc76","executionInfo":{"status":"ok","timestamp":1553671421075,"user_tz":-540,"elapsed":2047,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["# Test\n","model.eval()\n","acc = 0.\n","with torch.no_grad():\n","    for idx, (images, labels) in enumerate(test_loader):\n","        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","        y_hat = model(x) # (N, 10)\n","        loss = criterion(y_hat, y)\n","        _, indices = torch.max(y_hat, dim=-1)\n","        acc += torch.sum(indices == y).item()\n","print('*'*20, 'Test', '*'*20)\n","print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n","print('*'*46)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["******************** Test ********************\n","Step: 4685, Loss: 0.07549913227558136, Accuracy: 96.67999999999999 %\n","**********************************************\n"],"name":"stdout"}]},{"metadata":{"id":"nFoQkM7Mr0L8","colab_type":"code","outputId":"e1dfe3f0-3d46-4667-9fb0-bbad97a3d580","executionInfo":{"status":"ok","timestamp":1553671421076,"user_tz":-540,"elapsed":1738,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["idx = 7777 # 0 to 9999\n","img, y = mnist_test[idx]\n","img.shape, y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 28, 28]), 5)"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"qzrcr3vcr0L-","colab_type":"code","outputId":"7c043065-7a08-4d6f-ced8-bd29076a2cbe","executionInfo":{"status":"ok","timestamp":1553671421076,"user_tz":-540,"elapsed":1410,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":284}},"cell_type":"code","source":["imshow(img[0], cmap='gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f911bfe0da0>"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEEXCUBBFwlAQRcJQEEXCUBBFwng/wABbT1IXTJ8LwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"E1qgio9Rr0MC","colab_type":"code","outputId":"5f40087e-207b-4abe-8c1c-5cf6c283999b","executionInfo":{"status":"ok","timestamp":1553671421889,"user_tz":-540,"elapsed":634,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["sample = img.to(DEVICE)\n","out = model(sample)\n","_, idx = out.max(dim=-1)\n","idx"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5])"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"uYgsWotfr0ME","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"8cR6hl9hr0MF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Saving params.\n","torch.save(model.state_dict(), 'model.pkl')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6DpaWZhHCJJd","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}