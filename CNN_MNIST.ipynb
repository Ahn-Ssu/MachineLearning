{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W7zsPERtr0LC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Nets (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "9iL5KH63r0LE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If necessary, uncommand and run the following line to install pytorch\n",
        "#!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dEBe8KzEr0LJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "과거에는 Google Colab를 pytorch를 기본제공하지 않았으므로 Google Colab에서 pytorch를 사용하려면 먼저 pytorch를 설치해야 함.\n",
        "\n",
        "현재는 불필요함."
      ]
    },
    {
      "metadata": {
        "id": "YbUmP-VGVvcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QoPiqjikr0LT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**numpy**는 다차원 배열 및 벡터/ 행렬 기본 연산\n",
        "python으로 data science를 할 때 가장 기본이 되는 라이브러리 중 하나.\n",
        "\n",
        "**datetime** 학습/실행 시간 측정을 위한 package"
      ]
    },
    {
      "metadata": {
        "id": "kjpK8daar0LK",
        "colab_type": "code",
        "outputId": "16011164-50f5-4ee4-c5e8-b0d5fd7879fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision            \n",
        "import torch.nn as nn\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhNkRvYkr0LN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**torch**: pytorch package\n",
        "\n",
        "**torch.nn**: 신경망 모델에 Class들을 포함\n",
        "\n",
        "**torchvision**은 computer vision에 많이 사용되는 dataset, model, transform을 포함 (https://pytorch.org/docs/stable/torchvision/index.html)"
      ]
    },
    {
      "metadata": {
        "id": "ntWD5II587og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgsGVrkrAEPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data Loader: 데이터 로드를 위한 패키지 (Dataset + Sampler + Iterator)\n",
        "> * Dataset is an abstract class representing a dataset \n",
        "> * Sampler provides a way to iterate over indices of dataset elements\n",
        "\n",
        "\n",
        "See https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "metadata": {
        "id": "_tUvuvvPr0LO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Odn-STAQAmKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**dataset**: MNIST, fashion MNIST, COCO, LSUN, CIFAR, etc.\n",
        "\n",
        "**transforms**: algorithms for preprocessing or data augmentation\n",
        "\n",
        "See https://pytorch.org/docs/stable/torchvision/index.html to know datasets and transforms in torchvision"
      ]
    },
    {
      "metadata": {
        "id": "mtKXCay2kN5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using (deep) neural networks with python\n",
        "\n",
        "\n",
        "1. Define a network model\n",
        "\n",
        "2. Prepare data\n",
        "\n",
        "3. Train the model\n",
        "\n",
        "4. Evalute the model"
      ]
    },
    {
      "metadata": {
        "id": "eCc7O8M5r0LT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import matplotlib\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib.pyplot import imshow, imsave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgaevoCUr0LW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**matplotlib**: python visualization library"
      ]
    },
    {
      "metadata": {
        "id": "hYk9uq_Br0LW",
        "colab_type": "code",
        "outputId": "8b1f059a-837e-4f2a-89d9-c9510c0455e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'DNN'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL_NAME = DNN, DEVICE = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AhUqWS9-r0La",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n",
        "\n",
        "**torch.cuda.is_avaliable()**은 GPU가 사용가능한지를 판단하는 함수"
      ]
    },
    {
      "metadata": {
        "id": "8ljFCGEIXfCy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining a Neural Network model using pytorch\n",
        "\n",
        "1. Define a neural net model\n",
        "\n",
        "> * Define a model class inheriting **nn.module**\n",
        "\n",
        ">> nn.module is the base class of all layers/operators\n",
        "\n",
        ">* Define **__init__** function (constructor)\n",
        "\n",
        ">>  Create layers and operators\n",
        "\n",
        ">* Define **forward** function (forward propagation)\n",
        "\n",
        ">> Define how to compute the output from the input\n",
        "\n",
        "> Example\n",
        "\n",
        "~~~~\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Model, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "            self.conv2 = nn.Conv2d(20, 20, 5)           \n",
        "                   \n",
        "        def forward(self, x):\n",
        "            x = F.relu(self.conv1(x))\n",
        "            return F.relu(self.conv2(x))\n",
        "~~~~\n",
        "\n",
        "> Note! You don't need to backpropagation procedure, because pytorch provides **autograd**"
      ]
    },
    {
      "metadata": {
        "id": "sbpvoKXzr0Lb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HelloCNN(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple CNN Clssifier\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(HelloCNN, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            # (N, 1, 28, 28)\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            # (N, 32, 14, 14)\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            # (N, 64, 7, 7)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(7*7*64, 512),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_ = self.conv(x) # (N, 64, 7, 7)\n",
        "        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n",
        "        y_ = self.fc(y_)\n",
        "        return y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfM4wnwdr0Le",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**nn.Sequential()**: a sequential container.\n",
        "\n",
        "* Example of using Sequential\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(\n",
        "    nn.Conv2d(1,20,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(20,64,5),\n",
        "    nn.ReLU()\n",
        "    )\n",
        "~~~~\n",
        "* Example of using Sequential with OrderedDict\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1,20,5)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('conv2', nn.Conv2d(20,64,5)),\n",
        "    ('relu2', nn.ReLU())\n",
        "    ]))\n",
        "~~~~\n",
        "\n",
        "**nn.ModuleList**: a list-like container class \n",
        "\n",
        "* Example of using ModuleList\n",
        "\n",
        "~~~~\n",
        "  class MyModule(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(MyModule, self).__init__()\n",
        "          self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
        "            \n",
        "      def forward(self, x):\n",
        "          # ModuleList can act as an iterable, or be indexed using ints\n",
        "          for i, l in enumerate(self.linears):\n",
        "               x = self.linears[i // 2](x) + l(x)\n",
        "          return x\n",
        "                 \n",
        "~~~~"
      ]
    },
    {
      "metadata": {
        "id": "fyP-DP1Sr0Lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = HelloCNN().to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cyyU-712c1Np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Moves and/or casts the parameters and buffers. (CPU or GPU)"
      ]
    },
    {
      "metadata": {
        "id": "Z9-QvNvbksQj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading and preprocessing of data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Glhmh_OHlBMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform of input data"
      ]
    },
    {
      "metadata": {
        "id": "oq2EYzdBr0Lk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),                               # image to tensor\n",
        "     transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # normalize to \"(x-mean)/std\"\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vbb9TUIOz3tb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "2hE6ydS3r0Lm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**transforms**: torchvision에서 제공하는 transform 함수들이 있는 패키지.\n",
        "\n",
        "**ToTensor**: numpy array를 torch tensor로 변환.\n",
        "\n",
        "**Normalize**: 정규화 함수 output[channel] = (input[channel] - mean[channel]) / std[channel]"
      ]
    },
    {
      "metadata": {
        "id": "buibF906r0Lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "46ea5fd4-3a40-4ad1-c0bc-e6bb867373f8"
      },
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
        "mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8513286.89it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 129080.48it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2149819.05it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 48690.94it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYL_NEavr0Lo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."
      ]
    },
    {
      "metadata": {
        "id": "wGbeeCkCr0Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6_n0AFCmr0Lr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GR9GEof0r0Ls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n",
        "\n",
        "**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n",
        "\n",
        "**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."
      ]
    },
    {
      "metadata": {
        "id": "YH-t5coUmuOM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training neural network model\n",
        "\n",
        "\n",
        "Training procedure\n",
        "~~~~\n",
        "for epoch in range(max_epoch):\n",
        "    for input, target in dataset:    # retrieve input data and target labels\n",
        "        optimizer.zero_grad()     # reset gradient\n",
        "        output = model(input)     # forward propagation\n",
        "        loss = loss_fn(output, target)  # get loss value\n",
        "        loss.backward()           # back-propagation (compute gradient)     optimizer.step()          # update parameters with gradient\n",
        "~~~~"
      ]
    },
    {
      "metadata": {
        "id": "eeNx2EZKFoBP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# utility function to measure time\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEt4xYD4r0Lt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waSS2hrKr0Lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n",
        "\n",
        "**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."
      ]
    },
    {
      "metadata": {
        "id": "K4lF0ODwr0Lz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training procedure\n",
        "\n",
        "첫번째 for문: 원하는 epoch만큼 반복\n",
        "\n",
        "두번째 for문: training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n",
        "\n",
        "**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n",
        "\n",
        "**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n",
        "\n",
        "**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n",
        "\n",
        "**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n",
        "\n",
        "**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n",
        "\n",
        "**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n",
        "\n",
        "**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n",
        "\n",
        "**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n",
        "\n",
        "**torch.no_grad (Line 19)**: gradient를 계산하기 위해 추적하는 수고를 하지 않음\n",
        "\n",
        "**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n",
        "\n",
        "**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"
      ]
    },
    {
      "metadata": {
        "id": "zKCZDgDTNuY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reset loss history\n",
        "all_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "-KAxJESir0L0",
        "colab_type": "code",
        "outputId": "96026854-cac4-4c89-88d9-aa073f00a905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "max_epoch = 5        # maximum number of epochs\n",
        "step = 0             # initialize step counter variable\n",
        "\n",
        "plot_every = 200\n",
        "total_loss = 0 # Reset every plot_every iters\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        # Training Discriminator\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "        \n",
        "        y_hat = model(x) # (N, 10)  # forward propagation\n",
        "       \n",
        "        loss = criterion(y_hat, y)  # computing loss\n",
        "        total_loss += loss.item()\n",
        "          \n",
        "        optim.zero_grad()           # reset gradient\n",
        "        loss.backward()             # back-propagation (compute gradient)\n",
        "        optim.step()                # update parameters with gradient\n",
        "        \n",
        "        # periodically print loss\n",
        "        if step % 500 == 0:\n",
        "            print('Epoch({}): {}/{}, Step: {}, Loss: {}'.format(timeSince(start), epoch, max_epoch, step, loss.item()))\n",
        "        \n",
        "        if (step + 1) % plot_every == 0:\n",
        "            all_losses.append(total_loss / plot_every)\n",
        "            total_loss = 0\n",
        "        \n",
        "        # periodically evalute model on test data\n",
        "        if step % 1000 == 0:\n",
        "            model.eval()\n",
        "            acc = 0.\n",
        "            with torch.no_grad():   # disable autograd\n",
        "                for idx, (images, labels) in enumerate(test_loader):\n",
        "                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "                    y_hat = model(x) # (N, 10)\n",
        "                    loss = criterion(y_hat, y)\n",
        "                    _, indices = torch.max(y_hat, dim=-1)     # find maxmum along the last axis (argmax of each row)\n",
        "                                                              # ex) max_value, max_idx = torch.max(input, dim)\n",
        "                    acc += torch.sum(indices == y).item()     # count correctly classified samples\n",
        "                                                              # torch.sum() returns Tensor. Tensor.item() converts it to a value\n",
        "            print('*'*20, 'Test', '*'*20)\n",
        "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "            print('*'*46)\n",
        "            model.train()           # turn to train mode (enable autograd)\n",
        "        step += 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0m 0s): 0/5, Step: 0, Loss: 2.288383722305298\n",
            "******************** Test ********************\n",
            "Step: 0, Loss: 2.380215883255005, Accuracy: 10.280000000000001 %\n",
            "**********************************************\n",
            "Epoch(0m 6s): 0/5, Step: 500, Loss: 0.04912974685430527\n",
            "Epoch(0m 11s): 1/5, Step: 1000, Loss: 0.11026415973901749\n",
            "******************** Test ********************\n",
            "Step: 1000, Loss: 0.02675778791308403, Accuracy: 98.48 %\n",
            "**********************************************\n",
            "Epoch(0m 17s): 1/5, Step: 1500, Loss: 0.029742468148469925\n",
            "Epoch(0m 22s): 2/5, Step: 2000, Loss: 0.014918312430381775\n",
            "******************** Test ********************\n",
            "Step: 2000, Loss: 0.0018264246173202991, Accuracy: 98.57000000000001 %\n",
            "**********************************************\n",
            "Epoch(0m 29s): 2/5, Step: 2500, Loss: 0.03561990708112717\n",
            "Epoch(0m 35s): 3/5, Step: 3000, Loss: 0.06354859471321106\n",
            "******************** Test ********************\n",
            "Step: 3000, Loss: 0.0034596920013427734, Accuracy: 98.98 %\n",
            "**********************************************\n",
            "Epoch(0m 42s): 3/5, Step: 3500, Loss: 0.004750356078147888\n",
            "Epoch(0m 47s): 4/5, Step: 4000, Loss: 0.007072001695632935\n",
            "******************** Test ********************\n",
            "Step: 4000, Loss: 0.0006086063222028315, Accuracy: 99.09 %\n",
            "**********************************************\n",
            "Epoch(0m 54s): 4/5, Step: 4500, Loss: 0.05795302987098694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGfPwCZoN6LV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "90a9b022-7b31-4366-c973-ad785f92ef14"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9041dcaa20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ta_UwyT1r0L6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test and Visualize"
      ]
    },
    {
      "metadata": {
        "id": "6AwZsqeJr0L6",
        "colab_type": "code",
        "outputId": "76d60e96-e7dd-4421-d78c-8c14f3b208cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Test\n",
        "model.eval()\n",
        "acc = 0.\n",
        "with torch.no_grad():\n",
        "    for idx, (images, labels) in enumerate(test_loader):\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "        y_hat = model(x) # (N, 10)\n",
        "        loss = criterion(y_hat, y)\n",
        "        _, indices = torch.max(y_hat, dim=-1)\n",
        "        acc += torch.sum(indices == y).item()\n",
        "print('*'*20, 'Test', '*'*20)\n",
        "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "print('*'*46)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************** Test ********************\n",
            "Step: 4685, Loss: 0.003363437717780471, Accuracy: 99.03 %\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nFoQkM7Mr0L8",
        "colab_type": "code",
        "outputId": "e43a02f8-2f16-4293-83f3-1d6d8a10989f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "idx = 7777 # 0 to 9999\n",
        "img, y = mnist_test[idx]\n",
        "img.shape, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "qzrcr3vcr0L-",
        "colab_type": "code",
        "outputId": "c1469928-6e97-4d28-a0e4-07f352b55fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "imshow(img[0], cmap='gray')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f904e0f2470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "E1qgio9Rr0MC",
        "colab_type": "code",
        "outputId": "969e42ef-9b56-4878-a382-ef9842ff1134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "sample = img.to(DEVICE)\n",
        "out = model(sample)\n",
        "_, idx = out.max(dim=-1)\n",
        "idx"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c4c2af012d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-66f3acbacdcf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 64, 7, 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 64*7*7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 3-dimensional input of size [1, 28, 28] instead"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8cR6hl9hr0MF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving params.\n",
        "torch.save(model.state_dict(), 'model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}