{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_MNIST.ipynb","version":"0.3.2","provenance":[{"file_id":"1OuZwYHiFS3SdApVtP6Hzyt7mb65OVZRM","timestamp":1553673049050},{"file_id":"https://github.com/Yangyangii/pytorch-practice/blob/master/DNN.ipynb","timestamp":1553414179628}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"W7zsPERtr0LC","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Nets (CNN)"]},{"metadata":{"id":"9iL5KH63r0LE","colab_type":"code","colab":{}},"cell_type":"code","source":["# If necessary, uncommand and run the following line to install pytorch\n","#!pip install torch torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dEBe8KzEr0LJ","colab_type":"text"},"cell_type":"markdown","source":["과거에는 Google Colab를 pytorch를 기본제공하지 않았으므로 Google Colab에서 pytorch를 사용하려면 먼저 pytorch를 설치해야 함.\n","\n","현재는 불필요함."]},{"metadata":{"id":"YbUmP-VGVvcP","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import datetime"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QoPiqjikr0LT","colab_type":"text"},"cell_type":"markdown","source":["**numpy**는 다차원 배열 및 벡터/ 행렬 기본 연산\n","python으로 data science를 할 때 가장 기본이 되는 라이브러리 중 하나.\n","\n","**datetime** 학습/실행 시간 측정을 위한 package"]},{"metadata":{"id":"kjpK8daar0LK","colab_type":"code","outputId":"b3f0a763-5140-465b-d4f9-44d99bbdff7e","executionInfo":{"status":"ok","timestamp":1555376936733,"user_tz":-540,"elapsed":646,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import torch\n","import torchvision            \n","import torch.nn as nn\n","\n","print(torch.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1.0.1.post2\n"],"name":"stdout"}]},{"metadata":{"id":"LhNkRvYkr0LN","colab_type":"text"},"cell_type":"markdown","source":["**torch**: pytorch package\n","\n","**torch.nn**: 신경망 모델에 Class들을 포함\n","\n","**torchvision**은 computer vision에 많이 사용되는 dataset, model, transform을 포함 (https://pytorch.org/docs/stable/torchvision/index.html)"]},{"metadata":{"id":"ntWD5II587og","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.utils.data import DataLoader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YgsGVrkrAEPD","colab_type":"text"},"cell_type":"markdown","source":["Data Loader: 데이터 로드를 위한 패키지 (Dataset + Sampler + Iterator)\n","> * Dataset is an abstract class representing a dataset \n","> * Sampler provides a way to iterate over indices of dataset elements\n","\n","\n","See https://pytorch.org/docs/stable/data.html"]},{"metadata":{"id":"_tUvuvvPr0LO","colab_type":"code","colab":{}},"cell_type":"code","source":["from torchvision import datasets\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Odn-STAQAmKq","colab_type":"text"},"cell_type":"markdown","source":["**dataset**: MNIST, fashion MNIST, COCO, LSUN, CIFAR, etc.\n","\n","**transforms**: algorithms for preprocessing or data augmentation\n","\n","See https://pytorch.org/docs/stable/torchvision/index.html to know datasets and transforms in torchvision"]},{"metadata":{"id":"mtKXCay2kN5Z","colab_type":"text"},"cell_type":"markdown","source":["# Using (deep) neural networks with python\n","\n","\n","1. Define a network model\n","\n","2. Prepare data\n","\n","3. Train the model\n","\n","4. Evalute the model"]},{"metadata":{"id":"eCc7O8M5r0LT","colab_type":"code","colab":{}},"cell_type":"code","source":["#import matplotlib\n","\n","%matplotlib inline\n","from matplotlib.pyplot import imshow, imsave"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qgaevoCUr0LW","colab_type":"text"},"cell_type":"markdown","source":["**matplotlib**: python visualization library"]},{"metadata":{"id":"hYk9uq_Br0LW","colab_type":"code","outputId":"0ffb718c-0bc3-43ce-fb85-78b9c66fd8d1","executionInfo":{"status":"ok","timestamp":1555376943719,"user_tz":-540,"elapsed":331,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["MODEL_NAME = 'DNN'\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["MODEL_NAME = DNN, DEVICE = cuda\n"],"name":"stdout"}]},{"metadata":{"id":"AhUqWS9-r0La","colab_type":"text"},"cell_type":"markdown","source":["GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n","\n","**torch.cuda.is_avaliable()**은 GPU가 사용가능한지를 판단하는 함수"]},{"metadata":{"id":"8ljFCGEIXfCy","colab_type":"text"},"cell_type":"markdown","source":["## Defining a Neural Network model using pytorch\n","\n","1. Define a neural net model\n","\n","> * Define a model class inheriting **nn.module**\n","\n",">> nn.module is the base class of all layers/operators\n","\n",">* Define **__init__** function (constructor)\n","\n",">>  Create layers and operators\n","\n",">* Define **forward** function (forward propagation)\n","\n",">> Define how to compute the output from the input\n","\n","> Example\n","\n","~~~~\n","    class Model(nn.Module):\n","        def __init__(self):\n","            super(Model, self).__init__()\n","            self.conv1 = nn.Conv2d(1, 20, 5)\n","            self.conv2 = nn.Conv2d(20, 20, 5)           \n","                   \n","        def forward(self, x):\n","            x = F.relu(self.conv1(x))\n","            return F.relu(self.conv2(x))\n","~~~~\n","\n","> Note! You don't need to backpropagation procedure, because pytorch provides **autograd**"]},{"metadata":{"id":"sbpvoKXzr0Lb","colab_type":"code","colab":{}},"cell_type":"code","source":["class HelloCNN(nn.Module):\n","    \"\"\"\n","        Simple CNN Clssifier\n","    \"\"\"\n","    def __init__(self, num_classes=10):\n","        super(HelloCNN, self).__init__()\n","        \n","        self.conv = nn.Sequential(\n","            # (N, 1, 28, 28)\n","            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            # (N, 32, 14, 14)\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            # (N, 64, 7, 7)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(7*7*64, 512),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(512, num_classes),\n","        )\n","        \n","    def forward(self, x):\n","        y_ = self.conv(x) # (N, 64, 7, 7)\n","        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n","        y_ = self.fc(y_)\n","        return y_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BfM4wnwdr0Le","colab_type":"text"},"cell_type":"markdown","source":["**nn.Sequential()**: a sequential container.\n","\n","* Example of using Sequential\n","\n","~~~~\n","  model = nn.Sequential(\n","    nn.Conv2d(1,20,5),\n","    nn.ReLU(),\n","    nn.Conv2d(20,64,5),\n","    nn.ReLU()\n","    )\n","~~~~\n","* Example of using Sequential with OrderedDict\n","\n","~~~~\n","  model = nn.Sequential(OrderedDict([\n","    ('conv1', nn.Conv2d(1,20,5)),\n","    ('relu1', nn.ReLU()),\n","    ('conv2', nn.Conv2d(20,64,5)),\n","    ('relu2', nn.ReLU())\n","    ]))\n","~~~~\n","\n","**nn.ModuleList**: a list-like container class \n","\n","* Example of using ModuleList\n","\n","~~~~\n","  class MyModule(nn.Module):\n","      def __init__(self):\n","          super(MyModule, self).__init__()\n","          self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n","            \n","      def forward(self, x):\n","          # ModuleList can act as an iterable, or be indexed using ints\n","          for i, l in enumerate(self.linears):\n","               x = self.linears[i // 2](x) + l(x)\n","          return x\n","                 \n","~~~~"]},{"metadata":{"id":"fyP-DP1Sr0Lh","colab_type":"code","colab":{}},"cell_type":"code","source":["model = HelloCNN().to(DEVICE)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cyyU-712c1Np","colab_type":"text"},"cell_type":"markdown","source":["Moves and/or casts the parameters and buffers. (CPU or GPU)"]},{"metadata":{"id":"Z9-QvNvbksQj","colab_type":"text"},"cell_type":"markdown","source":["## Loading and preprocessing of data\n","\n"]},{"metadata":{"id":"Glhmh_OHlBMY","colab_type":"text"},"cell_type":"markdown","source":["Transform of input data"]},{"metadata":{"id":"oq2EYzdBr0Lk","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),                               # image to tensor\n","     transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # normalize to \"(x-mean)/std\"\n","    ])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vbb9TUIOz3tb","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"2hE6ydS3r0Lm","colab_type":"text"},"cell_type":"markdown","source":["**transforms**: torchvision에서 제공하는 transform 함수들이 있는 패키지.\n","\n","**ToTensor**: numpy array를 torch tensor로 변환.\n","\n","**Normalize**: 정규화 함수 output[channel] = (input[channel] - mean[channel]) / std[channel]"]},{"metadata":{"id":"buibF906r0Lm","colab_type":"code","colab":{}},"cell_type":"code","source":["mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n","mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lYL_NEavr0Lo","colab_type":"text"},"cell_type":"markdown","source":["**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n","\n","root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."]},{"metadata":{"id":"wGbeeCkCr0Lp","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 64"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6_n0AFCmr0Lr","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GR9GEof0r0Ls","colab_type":"text"},"cell_type":"markdown","source":["**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n","\n","**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n","\n","**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."]},{"metadata":{"id":"YH-t5coUmuOM","colab_type":"text"},"cell_type":"markdown","source":["## Training neural network model\n","\n","\n","Training procedure\n","~~~~\n","for epoch in range(max_epoch):\n","    for input, target in dataset:    # retrieve input data and target labels\n","        optimizer.zero_grad()     # reset gradient\n","        output = model(input)     # forward propagation\n","        loss = loss_fn(output, target)  # get loss value\n","        loss.backward()           # back-propagation (compute gradient)     optimizer.step()          # update parameters with gradient\n","~~~~"]},{"metadata":{"id":"eeNx2EZKFoBP","colab_type":"code","colab":{}},"cell_type":"code","source":["# utility function to measure time\n","\n","import time\n","import math\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pEt4xYD4r0Lt","colab_type":"code","colab":{}},"cell_type":"code","source":["# set loss function and optimizer\n","\n","criterion = nn.CrossEntropyLoss()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"waSS2hrKr0Lv","colab_type":"text"},"cell_type":"markdown","source":["**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n","\n","**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."]},{"metadata":{"id":"K4lF0ODwr0Lz","colab_type":"text"},"cell_type":"markdown","source":["### Training procedure\n","\n","첫번째 for문: 원하는 epoch만큼 반복\n","\n","두번째 for문: training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n","\n","**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n","\n","**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n","\n","**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n","\n","**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n","\n","**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n","\n","**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n","\n","**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n","\n","**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n","\n","**torch.no_grad (Line 19)**: gradient를 계산하기 위해 추적하는 수고를 하지 않음\n","\n","**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n","\n","**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"]},{"metadata":{"scrolled":true,"id":"-KAxJESir0L0","colab_type":"code","outputId":"5d46e172-b705-410e-94b4-232d339a60ac","executionInfo":{"status":"ok","timestamp":1555377013065,"user_tz":-540,"elapsed":54158,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":472}},"cell_type":"code","source":["max_epoch = 5        # maximum number of epochs\n","step = 0             # initialize step counter variable\n","\n","start = time.time()\n","\n","for epoch in range(max_epoch):\n","    for idx, (images, labels) in enumerate(train_loader):\n","        # Training Discriminator\n","        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","        \n","        y_hat = model(x) # (N, 10)  # forward propagation\n","       \n","        loss = criterion(y_hat, y)  # computing loss\n","        \n","        optim.zero_grad()           # reset gradient\n","        loss.backward()             # back-propagation (compute gradient)\n","        optim.step()                # update parameters with gradient\n","        \n","        # periodically print loss\n","        if step % 500 == 0:\n","            print('Epoch({}): {}/{}, Step: {}, Loss: {}'.format(timeSince(start), epoch, max_epoch, step, loss.item()))\n","        \n","        # periodically evalute model on test data\n","        if step % 1000 == 0:\n","            model.eval()\n","            acc = 0.\n","            with torch.no_grad():   # disable autograd\n","                for idx, (images, labels) in enumerate(test_loader):\n","                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","                    y_hat = model(x) # (N, 10)\n","                    loss = criterion(y_hat, y)\n","                    _, indices = torch.max(y_hat, dim=-1)     # find maxmum along the last axis (argmax of each row)\n","                                                              # ex) max_value, max_idx = torch.max(input, dim)\n","                    acc += torch.sum(indices == y).item()     # count correctly classified samples\n","                                                              # torch.sum() returns Tensor. Tensor.item() converts it to a value\n","            print('*'*20, 'Test', '*'*20)\n","            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n","            print('*'*46)\n","            model.train()           # turn to train mode (enable autograd)\n","        step += 1"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch(0m 0s): 0/5, Step: 0, Loss: 2.2922403812408447\n","******************** Test ********************\n","Step: 0, Loss: 2.7355687618255615, Accuracy: 13.750000000000002 %\n","**********************************************\n","Epoch(0m 6s): 0/5, Step: 500, Loss: 0.07125113904476166\n","Epoch(0m 11s): 1/5, Step: 1000, Loss: 0.02824196219444275\n","******************** Test ********************\n","Step: 1000, Loss: 0.03617427498102188, Accuracy: 98.56 %\n","**********************************************\n","Epoch(0m 17s): 1/5, Step: 1500, Loss: 0.019105322659015656\n","Epoch(0m 22s): 2/5, Step: 2000, Loss: 0.15466545522212982\n","******************** Test ********************\n","Step: 2000, Loss: 0.009560918435454369, Accuracy: 98.98 %\n","**********************************************\n","Epoch(0m 29s): 2/5, Step: 2500, Loss: 0.0006425976753234863\n","Epoch(0m 34s): 3/5, Step: 3000, Loss: 0.027721315622329712\n","******************** Test ********************\n","Step: 3000, Loss: 0.004072751849889755, Accuracy: 99.00999999999999 %\n","**********************************************\n","Epoch(0m 40s): 3/5, Step: 3500, Loss: 0.005077473819255829\n","Epoch(0m 45s): 4/5, Step: 4000, Loss: 0.00014138221740722656\n","******************** Test ********************\n","Step: 4000, Loss: 0.0021780587267130613, Accuracy: 98.79 %\n","**********************************************\n","Epoch(0m 51s): 4/5, Step: 4500, Loss: 0.015525102615356445\n"],"name":"stdout"}]},{"metadata":{"id":"ta_UwyT1r0L6","colab_type":"text"},"cell_type":"markdown","source":["## Test and Visualize"]},{"metadata":{"id":"6AwZsqeJr0L6","colab_type":"code","outputId":"f6d04559-6f57-4aff-d97b-14fe8a7c0404","executionInfo":{"status":"ok","timestamp":1555377014751,"user_tz":-540,"elapsed":54722,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["# Test\n","model.eval()\n","acc = 0.\n","with torch.no_grad():\n","    for idx, (images, labels) in enumerate(test_loader):\n","        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n","        y_hat = model(x) # (N, 10)\n","        loss = criterion(y_hat, y)\n","        _, indices = torch.max(y_hat, dim=-1)\n","        acc += torch.sum(indices == y).item()\n","print('*'*20, 'Test', '*'*20)\n","print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n","print('*'*46)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["******************** Test ********************\n","Step: 4685, Loss: 0.015991749241948128, Accuracy: 98.95 %\n","**********************************************\n"],"name":"stdout"}]},{"metadata":{"id":"nFoQkM7Mr0L8","colab_type":"code","outputId":"974dd8c5-8069-4657-d33b-ebd98540280b","executionInfo":{"status":"ok","timestamp":1555377014753,"user_tz":-540,"elapsed":54486,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["idx = 7777 # 0 to 9999\n","img, y = mnist_test[idx]\n","img.shape, y"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 28, 28]), 5)"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"qzrcr3vcr0L-","colab_type":"code","outputId":"7838fd7b-7df3-49b9-dec9-f2c690bf9a3c","executionInfo":{"status":"ok","timestamp":1555377014754,"user_tz":-540,"elapsed":53899,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":287}},"cell_type":"code","source":["imshow(img[0], cmap='gray')"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f27e96924e0>"]},"metadata":{"tags":[]},"execution_count":19},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADeRJREFUeJzt3X+MVPW5x/HPg4BGSiLcphtCzUUJ\nNkFjabOBm0huWq8CmibQP9RiYriRdFFRS6xGo3+IuWk0N7RV+YNkjUQwlELiD7BKW0rI5dY0DatR\n/NUWS2jKBhcVA6IJuPjcP/Zws8DOd4aZ82t93q9kszPnmTPnyWQ/e87M95z5mrsLQDxjqm4AQDUI\nPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMaWuTEz43RCoGDubq08rqM9v5ktMLO/mtn7ZvZA\nJ88FoFzW7rn9ZnaepL9JulbSAUm7JS1293cT67DnBwpWxp5/tqT33X2fu5+Q9GtJCzt4PgAl6iT8\nUyX9c9j9A9my05hZj5n1mVlfB9sCkLPCP/Bz915JvRKH/UCddLLn75d08bD738yWARgFOgn/bkkz\nzOwSMxsv6UeStubTFoCitX3Y7+6DZnanpN9JOk/SWnd/J7fOABSq7aG+tjbGe36gcKWc5ANg9CL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQhB8IivADQRF+IKhSp+hGMcaNG9ewdsEFFxS67WuuuSZZnz9/fsPasmXL8m7nNGvXrm1YGxgY\nSK67e/fuZP2VV15J1o8fP56s1wF7fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqNZes1sv6RPJZ2U\nNOju3U0ezyy9bZg7d26yvnLlyoa1q6++uqNtm6UnfC1zluc6efTRR5P1hx56qKROztbqLL15nOTz\nfXf/KIfnAVAiDvuBoDoNv0v6vZm9ZmY9eTQEoBydHvbPdfd+M/uGpO1m9hd33zX8Adk/Bf4xADXT\n0Z7f3fuz34ckvSBp9giP6XX37mYfBgIoV9vhN7MJZjbx1G1J8yS9nVdjAIrVyWF/l6QXsqGgsZJ+\n5e6/zaUrAIVrO/zuvk/St3PsJazp06cn62vWrEnWL7/88jzbgaQjR44k6y+99FJJnRSHoT4gKMIP\nBEX4gaAIPxAU4QeCIvxAUB1d0nvOG+OS3rbccMMNyfqmTZsK23adL+k9evRosr5v3762n/uuu+5K\n1l999dW2n7torV7Sy54fCIrwA0ERfiAowg8ERfiBoAg/EBThB4Jiiu4amDx5crK+dOnSkjrJ3969\nexvW3nzzzeS627dvT9Y//PDDZP3FF19M1qNjzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOXwNz\n5sxJ1ufNm1dSJ2c7efJksn7vvfcm6xs3bmxYGxgYaKsn5IM9PxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8E1XSc38zWSvqBpEPufkW2bLKkTZKmSdov6UZ3/6S4Nr/a6ny9/s0335ysb968uaROkLdW9vzP\nSFpwxrIHJO1w9xmSdmT3AYwiTcPv7rskHT5j8UJJ67Lb6yQtyrkvAAVr9z1/l7sfzG5/IKkrp34A\nlKTjc/vd3VNz8JlZj6SeTrcDIF/t7vkHzGyKJGW/DzV6oLv3unu3u3e3uS0ABWg3/FslLcluL5G0\nJZ92AJSlafjNbKOkP0n6lpkdMLOlkh6TdK2Z7ZV0TXYfwChiZc6vnvpsILLFixcn6xs2bCipk7N9\n8kn69I3Dh88cCDrdyy+/3LC2c+fO5LpbtnBA2Q53t1Yexxl+QFCEHwiK8ANBEX4gKMIPBEX4gaAY\n6quBmTNnJuurVq1K1hcsOPOiy/yYpUeNOvn7GRwcTNY//vjjZP3ZZ59N1lNDidu2bUuuO5ox1Acg\nifADQRF+ICjCDwRF+IGgCD8QFOEHgmKcfxQYOzb9bWsrVqxoWHv44YeT606YMCFZL3Kcv2ip6cUf\nf/zx5LqPPPJIsn7s2LG2eioD4/wAkgg/EBThB4Ii/EBQhB8IivADQRF+ICjG+YO76qqrkvV58+Yl\n6/fcc0+yPmZM4/3LhRdemFy3SqtXr07W77777pI6OXeM8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiB\noJqO85vZWkk/kHTI3a/Ilq2U9GNJH2YPe9DdX2m6Mcb5w7nooosa1m655Zbkus3q3d3dbfXUij17\n9iTrc+bMSdaPHz+eZzvnJM9x/mckjTQrxC/dfVb20zT4AOqlafjdfZekwyX0AqBEnbznv9PM9pjZ\nWjOblFtHAErRbvjXSJouaZakg5J+3uiBZtZjZn1m1tfmtgAUoK3wu/uAu5909y8lPSVpduKxve7e\n7e7FfToD4Jy1FX4zmzLs7g8lvZ1POwDKkv5OaElmtlHS9yR93cwOSHpY0vfMbJYkl7Rf0rICewRQ\nAK7nR211dXUl67t27UrWZ8yYkWc7p5k4cWKy/tlnnxW27Wa4nh9AEuEHgiL8QFCEHwiK8ANBEX4g\nqKbj/CjeZZddlqzX+Suu58+fn6xPnTq1Ya3Z1183Gy4rcjht27ZtyXqVl+zmhT0/EBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwTFOH9m/Pjxyfp1113XsHbbbbd1tO3Zsxt+EZIkadKk6r4i0Sx9dWizS8L7\n+/sb1jZv3pxc94477kjWZ82alax3YufOncn64OBgYdsuC3t+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwgqzFd3jx2bPqXhiSeeSNZvv/32PNsZNTod56+r1atXJ+v33Xdfsn7ixIk828kVX90NIInwA0ER\nfiAowg8ERfiBoAg/EBThB4Jqej2/mV0sab2kLkkuqdfdnzCzyZI2SZomab+kG939k+Ja7czy5cuT\n9ajj+F9lTz75ZMPa/fffn1y3zuP4eWllzz8o6afuPlPSv0labmYzJT0gaYe7z5C0I7sPYJRoGn53\nP+jur2e3P5X0nqSpkhZKWpc9bJ2kRUU1CSB/5/Se38ymSfqOpD9L6nL3g1npAw29LQAwSrT8HX5m\n9jVJz0la4e5Hh5/z7e7e6Lx9M+uR1NNpowDy1dKe38zGaSj4G9z9+WzxgJlNyepTJB0aaV1373X3\nbnfvzqNhAPloGn4b2sU/Lek9d//FsNJWSUuy20skbcm/PQBFaeWw/ypJt0h6y8zeyJY9KOkxSZvN\nbKmkf0i6sZgW8zEwMFB1C8hZs8tyU8N5X4UptjvVNPzu/kdJja4P/o982wFQFs7wA4Ii/EBQhB8I\nivADQRF+ICjCDwQV5qu7x4xJ/5/r7e1N1m+99dY82xk1Ov3q7iNHjjSsrV+/Prnupk2bkvW+vr5k\nPcJluSPhq7sBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFBhxvmbOf/885P1RYsafz/plVdemVz3pptu\nStYvvfTSZL1Iq1atSta/+OKLZP3YsWPJemrq888//zy5LtrDOD+AJMIPBEX4gaAIPxAU4QeCIvxA\nUIQfCIpxfuArhnF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU0/Cb2cVmttPM3jWzd8zsJ9nylWbW\nb2ZvZD/XF98ugLw0PcnHzKZImuLur5vZREmvSVok6UZJx9w9/W0Qpz8XJ/kABWv1JJ+xLTzRQUkH\ns9ufmtl7kqZ21h6Aqp3Te34zmybpO5L+nC2608z2mNlaM5vUYJ0eM+szs/TcSgBK1fK5/Wb2NUn/\nI+ln7v68mXVJ+kiSS/ovDb01SE5ox2E/ULxWD/tbCr+ZjZP0G0m/c/dfjFCfJuk37n5Fk+ch/EDB\ncruwx4amaX1a0nvDg599EHjKDyW9fa5NAqhOK5/2z5X0v5LekvRltvhBSYslzdLQYf9+ScuyDwdT\nz8WeHyhYrof9eSH8QPG4nh9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQf\nCIrwA0ERfiCopl/gmbOPJP1j2P2vZ8vqqK691bUvid7alWdv/9rqA0u9nv+sjZv1uXt3ZQ0k1LW3\nuvYl0Vu7quqNw34gKMIPBFV1+Hsr3n5KXXura18SvbWrkt4qfc8PoDpV7/kBVKSS8JvZAjP7q5m9\nb2YPVNFDI2a238zeymYernSKsWwatENm9vawZZPNbLuZ7c1+jzhNWkW91WLm5sTM0pW+dnWb8br0\nw34zO0/S3yRdK+mApN2SFrv7u6U20oCZ7ZfU7e6Vjwmb2b9LOiZp/anZkMzsvyUddvfHsn+ck9z9\n/pr0tlLnOHNzQb01mln6P1Xha5fnjNd5qGLPP1vS++6+z91PSPq1pIUV9FF77r5L0uEzFi+UtC67\nvU5Dfzyla9BbLbj7QXd/Pbv9qaRTM0tX+tol+qpEFeGfKumfw+4fUL2m/HZJvzez18ysp+pmRtA1\nbGakDyR1VdnMCJrO3FymM2aWrs1r186M13njA7+zzXX370q6TtLy7PC2lnzoPVudhmvWSJquoWnc\nDkr6eZXNZDNLPydphbsfHV6r8rUboa9KXrcqwt8v6eJh97+ZLasFd+/Pfh+S9IKG3qbUycCpSVKz\n34cq7uf/ufuAu5909y8lPaUKX7tsZunnJG1w9+ezxZW/diP1VdXrVkX4d0uaYWaXmNl4ST+StLWC\nPs5iZhOyD2JkZhMkzVP9Zh/eKmlJdnuJpC0V9nKauszc3GhmaVX82tVuxmt3L/1H0vUa+sT/75Ie\nqqKHBn1dKunN7OedqnuTtFFDh4FfaOizkaWS/kXSDkl7Jf1B0uQa9fashmZz3qOhoE2pqLe5Gjqk\n3yPpjezn+qpfu0RflbxunOEHBMUHfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvo/y76ebXSU\nlzQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"E1qgio9Rr0MC","colab_type":"code","outputId":"c4cdbcd1-6e10-4f18-e0e4-44aebc60261f","executionInfo":{"status":"error","timestamp":1555377014754,"user_tz":-540,"elapsed":53307,"user":{"displayName":"Injung Kim","photoUrl":"","userId":"13406367766306429798"}},"colab":{"base_uri":"https://localhost:8080/","height":1011}},"cell_type":"code","source":["sample = img.to(DEVICE)\n","out = model(sample)\n","_, idx = out.max(dim=-1)\n","idx"],"execution_count":20,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c4c2af012d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-66f3acbacdcf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 64, 7, 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 64*7*7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 3-dimensional input of size [1, 28, 28] instead"]}]},{"metadata":{"id":"8cR6hl9hr0MF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Saving params.\n","torch.save(model.state_dict(), 'model.pkl')"],"execution_count":0,"outputs":[]}]}