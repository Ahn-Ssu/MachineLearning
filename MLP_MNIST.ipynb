{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/MLP_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W7zsPERtr0LC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi-Layer Perceptron (MLP)"
      ]
    },
    {
      "metadata": {
        "id": "9iL5KH63r0LE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If pytorch is not installed, uncommand and run the following line to install pytorch\n",
        "#!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbUmP-VGVvcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QoPiqjikr0LT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**numpy**는 다차원 배열 및 벡터/ 행렬 기본 연산\n",
        "python으로 data science를 할 때 가장 기본이 되는 라이브러리 중 하나."
      ]
    },
    {
      "metadata": {
        "id": "kjpK8daar0LK",
        "colab_type": "code",
        "outputId": "5beb90ea-c74d-4c3a-c975-bd52569d958a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision            \n",
        "import torch.nn as nn\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhNkRvYkr0LN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**torch**: pytorch package\n",
        "\n",
        "**torch.nn**: 신경망 모델에 Class들을 포함\n",
        "\n",
        "**torchvision**은 computer vision에 많이 사용되는 dataset, model, transform을 포함 (https://pytorch.org/docs/stable/torchvision/index.html)"
      ]
    },
    {
      "metadata": {
        "id": "ntWD5II587og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgsGVrkrAEPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data Loader: 데이터 로드를 위한 패키지 (Dataset + Sampler + Iterator)\n",
        "> * Dataset is an abstract class representing a dataset \n",
        "> * Sampler provides a way to iterate over indices of dataset elements\n",
        "> * Iterator: an object representing a stream of data. Repeated calls to the iterator’s next() method return successive items in the stream.\n",
        "\n",
        "See https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "metadata": {
        "id": "_tUvuvvPr0LO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Odn-STAQAmKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**dataset**: MNIST, fashion MNIST, COCO, LSUN, CIFAR, etc.\n",
        "\n",
        "**transforms**: algorithms for preprocessing or data augmentation\n",
        "\n",
        "See https://pytorch.org/docs/stable/torchvision/index.html to know datasets and transforms in torchvision"
      ]
    },
    {
      "metadata": {
        "id": "mtKXCay2kN5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using (deep) neural networks with python\n",
        "\n",
        "\n",
        "1. Define a network model\n",
        "\n",
        "2. Prepare data\n",
        "\n",
        "3. Train the model\n",
        "\n",
        "4. Use or evalute the model\n"
      ]
    },
    {
      "metadata": {
        "id": "eCc7O8M5r0LT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#import matplotlib\n",
        "\n",
        "from matplotlib.pyplot import imshow, imsave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgaevoCUr0LW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**matplotlib**: python visualization library"
      ]
    },
    {
      "metadata": {
        "id": "hYk9uq_Br0LW",
        "colab_type": "code",
        "outputId": "345f822b-e84f-4468-dc55-e7910bfb9bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'MLP'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL_NAME = MLP, DEVICE = cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AhUqWS9-r0La",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n",
        "\n",
        "**torch.cuda.is_avaliable()**은 GPU가 사용가능한지를 판단하는 함수"
      ]
    },
    {
      "metadata": {
        "id": "8ljFCGEIXfCy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining a Neural Network model using pytorch\n",
        "\n",
        "1. Define a neural net model\n",
        "\n",
        "> * Define a model class inheriting **nn.module**\n",
        "\n",
        ">> nn.module is the base class of all layers/operators\n",
        "\n",
        ">* Define **\\_\\_init\\_\\_** function (constructor)\n",
        "\n",
        ">>  Create layers and operators\n",
        "\n",
        ">* Define **forward** function (forward propagation)\n",
        "\n",
        ">> Define how to compute the output from the input\n",
        "\n",
        "> Example\n",
        "\n",
        "```\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Model, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "            self.conv2 = nn.Conv2d(20, 20, 5)           \n",
        "                   \n",
        "        def forward(self, x):\n",
        "            x = F.relu(self.conv1(x))\n",
        "            return F.relu(self.conv2(x))\n",
        "```            \n",
        "\n",
        "\n",
        "> Note! You don't need to backpropagation procedure, because pytorch provides **autograd**"
      ]
    },
    {
      "metadata": {
        "id": "sbpvoKXzr0Lb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HelloMLP(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(HelloMLP, self).__init__()\n",
        "        self.mlp = nn.Sequential(             # a sequential container\n",
        "            # 1st layer\n",
        "            nn.Linear(input_size, 64),        # matrix multiplication (fully connected layer)            \n",
        "            nn.Tanh(),                        # activation function (nn.ReLU(), nn.Tanh(), nn.Sigmoid(), etc.)\n",
        "            \n",
        "            # 2nd layer\n",
        "            nn.Linear(64, 64),                # matrix multiplication (fully connected layer)\n",
        "            nn.ReLU(),                        # activation function\n",
        "            \n",
        "            # 3rd (output) layer\n",
        "            nn.Linear(64, num_classes),\n",
        "            # nn.Softmax(),                   # not necessary because CrossEntopyLoss class includes Softmax\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_ = x.view(x.size(0), -1)            # Reshape input tensor (N, 28, 28) --> (N, 784)\n",
        "        y_ = self.mlp(y_)                     # compute \n",
        "        return y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfM4wnwdr0Le",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**nn.Sequential()**: a sequential container.\n",
        "\n",
        "* Example of using Sequential\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(\n",
        "    nn.Conv2d(1,20,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(20,64,5),\n",
        "    nn.ReLU()\n",
        "    )\n",
        "~~~~\n",
        "* Example of using Sequential with OrderedDict\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1,20,5)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('conv2', nn.Conv2d(20,64,5)),\n",
        "    ('relu2', nn.ReLU())\n",
        "    ]))\n",
        "~~~~\n",
        "\n",
        "**nn.ModuleList()**: a list-like container class \n",
        "\n",
        "* Example of using ModuleList\n",
        "\n",
        "~~~~\n",
        "  class MyModule(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(MyModule, self).__init__()\n",
        "          self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
        "            \n",
        "      def forward(self, x):\n",
        "          # ModuleList can act as an iterable, or be indexed using ints\n",
        "          for i, l in enumerate(self.linears):\n",
        "               x = self.linears[i // 2](x) + l(x)\n",
        "          return x\n",
        "                 \n",
        "~~~~"
      ]
    },
    {
      "metadata": {
        "id": "fyP-DP1Sr0Lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = HelloMLP().to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cyyU-712c1Np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Moves and/or casts the parameters and buffers. (CPU or GPU)"
      ]
    },
    {
      "metadata": {
        "id": "Z9-QvNvbksQj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading and preprocessing data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Glhmh_OHlBMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform of input data"
      ]
    },
    {
      "metadata": {
        "id": "oq2EYzdBr0Lk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),                               # image to tensor\n",
        "     transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # normalize to \"(x-mean)/std\"\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hE6ydS3r0Lm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**transforms**: torchvision에서 제공하는 transform 함수들이 있는 패키지.\n",
        "\n",
        "**ToTensor**: numpy array를 torch tensor로 변환.\n",
        "\n",
        "**Normalize**: 정규화 함수 output[channel] = (input[channel] - mean[channel]) / std[channel]"
      ]
    },
    {
      "metadata": {
        "id": "buibF906r0Lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
        "mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYL_NEavr0Lo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."
      ]
    },
    {
      "metadata": {
        "id": "wGbeeCkCr0Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6_n0AFCmr0Lr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GR9GEof0r0Ls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n",
        "\n",
        "**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n",
        "\n",
        "**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."
      ]
    },
    {
      "metadata": {
        "id": "YH-t5coUmuOM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training neural network model\n",
        "\n",
        "\n",
        " Typical training procedure\n",
        "```\n",
        "for epoch in range(max_epoch): \n",
        "    for input, target in dataset:     # retrieve input data and target labels\n",
        "        optimizer.zero_grad()           # reset gradient\n",
        "        output = model(input)           # forward propagation\n",
        "        loss = loss_fn(output, target)  # get loss value\n",
        "        loss.backward()                 # back-propagation (compute gradient)\n",
        "        optimizer.step()                # update parameters with gradient\n",
        "        \n",
        "        # Recommendation: periodically print log message including current step, loss, accuracy, etc.\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "FRw6ytc9DZCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# utility function to measure time\n",
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEt4xYD4r0Lt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# set optimizer\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waSS2hrKr0Lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n",
        "\n",
        "**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."
      ]
    },
    {
      "metadata": {
        "id": "K4lF0ODwr0Lz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training procedure\n",
        "\n",
        "첫번째 for문: 원하는 epoch만큼 반복\n",
        "\n",
        "두번째 for문: training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n",
        "\n",
        "**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n",
        "\n",
        "**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n",
        "\n",
        "**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n",
        "\n",
        "**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n",
        "\n",
        "**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n",
        "\n",
        "**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n",
        "\n",
        "**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n",
        "\n",
        "**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n",
        "\n",
        "**torch.no_grad (Line 19)**: gradient를 계산하기 위해 추적하는 수고를 하지 않음\n",
        "\n",
        "**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n",
        "\n",
        "**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"
      ]
    },
    {
      "metadata": {
        "id": "hjKZyJhvMibz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reset loss history\n",
        "all_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "-KAxJESir0L0",
        "colab_type": "code",
        "outputId": "cef8aeb3-e71c-40db-babb-a5d9906fa325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "cell_type": "code",
      "source": [
        "max_epoch = 5        # maximum number of epochs\n",
        "step = 0             # initialize step counter variable\n",
        "\n",
        "plot_every = 200\n",
        "total_loss = 0 # Reset every plot_every iters\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "\n",
        "        y_hat = model(x)            # forward propagation, y_hat.shape = (N, 10) \n",
        "       \n",
        "        loss = loss_fn(y_hat, y)    # computing loss\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        optim.zero_grad()           # reset gradient\n",
        "        loss.backward()             # back-propagation (compute gradient)\n",
        "        optim.step()                # update parameters with gradient\n",
        "        \n",
        "        # periodically print loss\n",
        "        if step % 500 == 0:\n",
        "            print('Epoch({}): {}/{}, Step: {}, Loss: {}'.format(timeSince(start), epoch, max_epoch, step, loss.item()))\n",
        "        \n",
        "        if (step + 1) % plot_every == 0:\n",
        "            all_losses.append(total_loss / plot_every)\n",
        "            total_loss = 0\n",
        "        \n",
        "        # periodically evalute model on test data\n",
        "        if step % 1000 == 0:\n",
        "            model.eval()\n",
        "            acc = 0.\n",
        "            with torch.no_grad():   # disable autograd\n",
        "                for idx, (images, labels) in enumerate(test_loader):\n",
        "                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "                    y_hat = model(x) # (N, 10)\n",
        "                    loss = loss_fn(y_hat, y)\n",
        "                    _, indices = torch.max(y_hat, dim=-1)     # find maxmum along the last axis (argmax of each row)\n",
        "                                                              # ex) max_value, max_idx = torch.max(input, dim)\n",
        "                    acc += torch.sum(indices == y).item()     # count correctly classified samples\n",
        "                                                              # torch.sum() returns Tensor. Tensor.item() converts it to a value\n",
        "            print('*'*20, 'Test', '*'*20)\n",
        "            print('Step: {}, Loss: {}, test accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "            print('*'*46)\n",
        "            model.train()           # turn to train mode (enable autograd)\n",
        "        step += 1"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0m 0s): 0/5, Step: 0, Loss: 2.314640998840332\n",
            "******************** Test ********************\n",
            "Step: 0, Loss: 2.262996196746826, test accuracy: 12.15 %\n",
            "**********************************************\n",
            "Epoch(0m 6s): 0/5, Step: 500, Loss: 0.3385827839374542\n",
            "Epoch(0m 11s): 1/5, Step: 1000, Loss: 0.16042497754096985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9e830d2308ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# disable autograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 1, 28, 28), (N, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5DSxYhBXMldi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ta_UwyT1r0L6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test and Visualize"
      ]
    },
    {
      "metadata": {
        "id": "6AwZsqeJr0L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test\n",
        "model.eval()\n",
        "acc = 0.\n",
        "with torch.no_grad():\n",
        "    for idx, (images, labels) in enumerate(test_loader):\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "        y_hat = model(x) # (N, 10)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        _, indices = torch.max(y_hat, dim=-1)\n",
        "        acc += torch.sum(indices == y).item()\n",
        "print('*'*20, 'Test', '*'*20)\n",
        "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "print('*'*46)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFoQkM7Mr0L8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = 1415 # 0 to 9999\n",
        "img, y = mnist_test[idx]\n",
        "img.shape, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qzrcr3vcr0L-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imshow(img[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1qgio9Rr0MC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample = img.to(DEVICE)\n",
        "out = model(sample)\n",
        "_, idx = out.max(dim=-1)\n",
        "np.squeeze(idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cR6hl9hr0MF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save parameters, if necessary.\n",
        "torch.save(model.state_dict(), 'model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JLxD2e5tSh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}